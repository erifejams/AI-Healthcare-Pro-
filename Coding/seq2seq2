#CREATE TRAINING AND TEST LIST
#Tokenizing the training data
import os

#have to include this or some libraries(in tensorflow) are not found before importing tensorflow
#apparently this problem was only found in Python 3.9.10 not python
#MAKE SURE TO ALWAYS INCLUDE IN THE FILE **IMPORTANT
os.add_dll_directory("C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin")


from keras.models import Model
from keras.layers import Input, LSTM, Dense
import numpy as np
import TrainingModel as tm
import pandas as pd
from sklearn.model_selection import train_test_split

from keras import backend as K
K.clear_session()

batch_size = 1  # Batch size for training.
epochs = 100  # Number of epochs to train for.
latent_dim = 256  # Latent dimensionality of the encoding space.
num_samples = 200  # Number of samples to train on.
# Path to the data txt file on disk.
#data_path = 'fra.txt'#'fra-eng/fra.txt'
training = pd.read_csv (r'Data/trainingData.csv')
import csv

#print(header)
#print(rows)
rows = []

# Vectorize the data.
input_texts = []
target_texts = []
input_characters = set()
target_characters = set()
with open("Data/trainingData.csv", 'r') as f:
    csvreader = csv.reader(f)
    header = next(csvreader)
    for row in csvreader:
        rows.append(row)

# Split data into train and test set
X_train, X_test, y_train, y_test = train_test_split(tm.question_padded, tm.answer_padded, test_size=0.1, random_state=0)
num_encoder_tokens = num_samples
num_decoder_tokens = num_samples


encoder_input_data = np.zeros(
    (1000, tm.max_question_len, num_encoder_tokens),
    dtype='float32')
decoder_input_data = np.zeros(
    (1000, tm.max_answer_len, num_decoder_tokens),
    dtype='float32')
decoder_target_data = np.zeros(
    (1000, tm.max_answer_len, num_decoder_tokens),
    dtype='float32')

print("encoder_input_data",encoder_input_data.shape)
print("decoder_input_data",decoder_input_data.shape)
print("decoder_target_data",decoder_target_data.shape)
print("**************")


# Define an input sequence and process it.
encoder_inputs = Input(shape=(None, num_encoder_tokens))
encoder = LSTM(latent_dim, return_state=True)
encoder_outputs, state_h, state_c = encoder(encoder_inputs)
# We discard `encoder_outputs` and only keep the states.
encoder_states = [state_h, state_c]

# Set up the decoder, using `encoder_states` as initial state.
decoder_inputs = Input(shape=(None, num_decoder_tokens))
# We set up our decoder to return full output sequences,
# and to return internal states as well. We don't use the
# return states in the training model, but we will use them in inference.
decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)
decoder_outputs, _, _ = decoder_lstm(decoder_inputs,
                                     initial_state=encoder_states)
decoder_dense = Dense(num_decoder_tokens, activation='softmax')
decoder_outputs = decoder_dense(decoder_outputs)

# Define the model that will turn
# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`
model = Model([encoder_inputs, decoder_inputs], decoder_outputs)

# Run training
model.compile(optimizer='rmsprop', loss='categorical_crossentropy',
              metrics=['accuracy'])
model.fit([encoder_input_data, decoder_input_data], decoder_target_data,
          batch_size=batch_size,
          epochs=epochs,
          validation_split=0.2)
# Save model
model.save('s2s.h5')